{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入必要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "import pandas as pd\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForSeq2Seq, TrainingArguments, Trainer, BitsAndBytesConfig, GenerationConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version:  2.2.1+cu121\n",
      "transformers version:  4.39.0\n"
     ]
    }
   ],
   "source": [
    "print(\"torch version: \", torch.__version__)\n",
    "print(\"transformers version: \", transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 2048    # 分词器会将一个中文字切分为多个token，因此需要放开一些最大长度，保证数据的完整性\n",
    "data_path = \"../data/emo_1234_xtuner.json\"\n",
    "pretrained_model_name_or_path = \"../models/internlm2-chat-1_8b\"\n",
    "work_dir = \"../work_dirs/internlm2_chat_1_8b_qlora_emo_e3_hf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 载入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['conversation'],\n",
       "    num_rows: 16011\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = Dataset.from_json(data_path)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversation': [{'input': '医生，我最近总是感到很焦虑，尤其是在学业上。我有个特别崇拜的同学，他好像在各方面都比我优秀，我总觉得自己怎么努力也追不上他，这让我压力特别大。',\n",
       "   'output': '你好，首先感谢你对我敞开心扉。你的这种情绪其实很常见，这是由于过度比较和自我期待过高引发的焦虑情绪。我们要认识到每个人都有自己的发展节奏和优势，与他人比较并不是衡量自身价值的唯一标准。你可以试着列出自己在学习和其他方面的优点，同时理解并接纳自己的不足。我们可以一步步来，先从调整自我认知开始。',\n",
       "   'system': '现在你是一个心理专家，我有一些心理问题，请你用专业的知识帮我解决。'},\n",
       "  {'input': '是的，我知道应该理性看待，但就是忍不住会去比较。我甚至晚上会因为这个睡不着觉，总想着怎样才能像他那样出色。',\n",
       "   'output': '了解你的情况后，我建议你在睡前尝试进行放松训练，比如深呼吸、冥想等方法，有助于改善睡眠质量。另外，设定实际可达的目标也是很重要的，避免给自己设定过于严苛的标准。你是否可以具体描述一下你在学业上的困扰，我们一起看看如何制定一个适合你的个人提升计划？',\n",
       "   'system': None},\n",
       "  {'input': '我在数学方面总是比他落后很多，我尝试了很多方法提高，但还是觉得力不从心。',\n",
       "   'output': '对于数学学习困难的问题，我们可以探讨更具针对性的学习策略，如分解复杂问题为小块、寻找优质的学习资源或参加学习小组等。同时，也要建立对失败的正确认识，失败是成功的垫脚石，每一次错误都是我们进步的机会。接下来，我会推荐一些有效的学习技巧，并鼓励你定期与我分享进展，以便我们根据实际情况进行调整。\\n医生：另外，请记住，寻求帮助也是一种能力，如果你感到持续的压力和焦虑影响了生活和学习，不妨考虑找学校的心理辅导老师或者进一步接受专业心理咨询。心理健康与学业成就同样重要，让我们一起关注并呵护它。',\n",
       "   'system': None}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InternLM2Tokenizer(name_or_path='../models/internlm2-chat-1_8b', vocab_size=92544, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '</s>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|action_start|>', '<|action_end|>', '<|interpreter|>', '<|plugin|>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t92538: AddedToken(\"<|plugin|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t92539: AddedToken(\"<|interpreter|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t92540: AddedToken(\"<|action_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t92541: AddedToken(\"<|action_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t92542: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t92543: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path, use_fast=False, trust_remote_code=True)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 0, 92543, 92542, 92541, 92540, 92539, 92538]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " '</s>',\n",
       " '<unk>',\n",
       " '<|im_start|>',\n",
       " '<|im_end|>',\n",
       " '<|action_start|>',\n",
       " '<|action_end|>',\n",
       " '<|interpreter|>',\n",
       " '<|plugin|>']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.bos_token_id, tokenizer.eos_token_id, tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 92543, 92542]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"<s>[UNUSED_TOKEN_146][UNUSED_TOKEN_145]\", add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' <s><|im_start|><|im_end|>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([1, 92543, 92542], skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 92543, 92542]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"<s><|im_start|><|im_end|>\", add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/InternLM/xtuner/blob/main/xtuner/utils/templates.py#L24\n",
    "internlm2_chat = dict(\n",
    "    SYSTEM = '<|im_start|>system\\n{system}<|im_end|>\\n',\n",
    "    INSTRUCTION = ('<|im_start|>user\\n{input}<|im_end|>\\n'\n",
    "                   '<|im_start|>assistant\\n'),\n",
    "    SUFFIX = '<|im_end|>',\n",
    "    SUFFIX_AS_EOS = True,\n",
    "    SEP = '\\n',\n",
    "    STOP_WORDS = ['<|im_end|>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/internlm/internlm2-chat-1_8b/blob/main/modeling_internlm2.py#L1136-L1146\n",
    "def build_inputs(\n",
    "    tokenizer,\n",
    "    query: str,\n",
    "    history: list[tuple[str, str]] | None = None,\n",
    "    meta_instruction = \"\"\n",
    ") -> tuple[str, list]:\n",
    "    history = [] if history is None else list(history)\n",
    "    if tokenizer.add_bos_token:\n",
    "        prompt = \"\"\n",
    "    else:\n",
    "        prompt = tokenizer.bos_token\n",
    "    if meta_instruction:\n",
    "        prompt += f\"\"\"<|im_start|>system\\n{meta_instruction}<|im_end|>\\n\"\"\"\n",
    "    for record in history:\n",
    "        prompt += f\"\"\"<|im_start|>user\\n{record[0]}<|im_end|>\\n<|im_start|>assistant\\n{record[1]}<|im_end|>\\n\"\"\"\n",
    "    prompt += f\"\"\"<|im_start|>user\\n{query}<|im_end|>\\n<|im_start|>assistant\\n\"\"\"\n",
    "    return prompt, tokenizer([prompt], return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s><|im_start|>system\\n我是系统<|im_end|>\\n<|im_start|>user\\n你好<|im_end|>\\n<|im_start|>assistant\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_inputs('你好')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_func(example):\n",
    "    # print(example)\n",
    "    # {\n",
    "    #    'conversation': [\n",
    "    #         {\n",
    "    #             'input': '医生，我最近总是感到很焦虑，尤其是在学业上。我有个特别崇拜的同学，他好像在各方面都比我优秀，我总觉得自己怎么努力也追不上他，这让我压力特别大。\\n\\n',\n",
    "    #             'output': '你好，首先感谢你对我敞开心扉。你的这种情绪其实很常见，这是由于过度比较和自我期待过高引发的焦虑情绪。我们要认识到每个人都有自己的发展节奏和优势，与他人比较并不是衡量自身价值的唯一标准。你可以试着列出自己在学习和其他方面的优点，同时理解并接纳自己的不足。我们可以一步步来，先从调整自我认知开始。\\n\\n',\n",
    "    #             'system': '现在你是一个心理专家，我有一些心理问题，请你用专业的知识帮我解决。'\n",
    "    #         },\n",
    "    #         {\n",
    "    #             'input': '是的，我知道应该理性看待，但就是忍不住会去比较。我甚至晚上会因为这个睡不着觉，总想着怎样才能像他那样出色。\\n\\n',\n",
    "    #             'output': '了解你的情况后，我建议你在睡前尝试进行放松训练，比如深呼吸、冥想等方法，有助于改善睡眠质量。另外，设定实际可达的目标也是很重要的，避免给自己设定过于严苛的标准。你是否可以具体描述一下你在学业上的困扰，我们一起看看如何制定一个适合你的个人提升计划？\\n\\n',\n",
    "    #             'system': None\n",
    "    #         }\n",
    "    #     ]\n",
    "    # }\n",
    "\n",
    "    # 开始的 bos token\n",
    "    input_ids = [tokenizer.bos_token_id]\n",
    "    attention_mask = [1]\n",
    "    labels = [-100]\n",
    "\n",
    "    # 多轮对话\n",
    "    for i, conversation in enumerate(example['conversation']):\n",
    "        # 第一轮添加system指令\n",
    "        if i == 0:\n",
    "            text = f\"<|im_start|>system\\n{conversation['system']}<|im_end|>\\n<|im_start|>user\\n{conversation['input']}<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "        else:\n",
    "            text = f\"<|im_start|>user\\n{conversation['input']}<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "        instruction = tokenizer(text, add_special_tokens=False)  # add_special_tokens 不在开头加 special_tokens\n",
    "        response = tokenizer(f\"{conversation['output']}<|im_end|>\\n\", add_special_tokens=False)\n",
    "        input_ids += instruction[\"input_ids\"] + response[\"input_ids\"]\n",
    "        attention_mask += instruction[\"attention_mask\"] + response[\"attention_mask\"]\n",
    "        labels += [-100] * len(instruction[\"input_ids\"]) + response[\"input_ids\"]\n",
    "\n",
    "    # 结束的 eos token\n",
    "    input_ids += [tokenizer.eos_token_id]\n",
    "    attention_mask += [1]                   # 因为eos token咱们也是要关注的所以 补充为1\n",
    "    labels += [tokenizer.eos_token_id]\n",
    "\n",
    "    if len(input_ids) > MAX_LENGTH:  # 做一个截断\n",
    "        input_ids = input_ids[:MAX_LENGTH]\n",
    "        attention_mask = attention_mask[:MAX_LENGTH]\n",
    "        labels = labels[:MAX_LENGTH]\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 16011\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove_columns: map 后会移除这一列\n",
    "tokenized_id = ds.map(process_func, remove_columns=ds.column_names)\n",
    "tokenized_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conversation']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'labels'])\n",
      "[1, 92543, 9081, 364, 68293, 60403, 68625, 68831, 69212, 60353, 60363, 71525, 68831, 68287, 60353, 78463, 60379, 70159, 68580, 72863, 68530, 60355, 92542, 364, 92543, 1008, 364, 69156, 60353, 60363, 68848, 68965, 69836, 60427, 71833, 60353, 78931, 77649, 60370, 60355, 60363, 69054, 68425, 78126, 72246, 60353, 60404, 69123, 60361, 77801, 60406, 72256, 68877, 60353, 60363, 60649, 70868, 68288, 68626, 60395, 61286, 69842, 60404, 60353, 60376, 68678, 68912, 68425, 60368, 60355, 92542, 364, 92543, 525, 11353, 364, 77230, 60353, 68400, 69894, 60403, 69880, 63612, 69166, 64886, 60355, 68364, 68381, 69209, 68377, 60427, 69305, 60353, 68472, 68560, 71631, 68324, 60381, 69396, 70271, 76436, 90530, 71833, 69209, 60355, 69897, 80966, 78747, 68304, 68357, 71228, 60381, 69203, 60353, 60510, 70535, 68324, 69461, 77546, 69238, 76906, 69362, 68559, 60355, 69686, 75630, 76048, 73799, 68352, 71842, 69834, 71280, 60353, 68405, 68865, 60573, 82567, 68304, 69490, 60355, 68931, 78705, 60383, 60353, 89901, 68660, 69396, 71582, 68301, 60355, 92542, 364, 92543, 1008, 364, 74212, 60353, 71275, 68402, 73514, 75919, 60353, 60499, 68259, 72978, 89828, 68324, 60355, 88720, 68742, 60382, 79472, 76897, 60610, 60353, 60649, 70282, 82979, 60770, 60404, 70178, 75737, 60355, 92542, 364, 92543, 525, 11353, 364, 68505, 68364, 68358, 60375, 60353, 60363, 68571, 70923, 74541, 69702, 68274, 70900, 69233, 60353, 68522, 60887, 69930, 60359, 87245, 60455, 68256, 60353, 72195, 69715, 86038, 60355, 68721, 60353, 70579, 68763, 75936, 74462, 74727, 69034, 60353, 68840, 70637, 70579, 70871, 61274, 64221, 76017, 60355, 79018, 68251, 68592, 69401, 68300, 70923, 77649, 68365, 74112, 60353, 75173, 68518, 68343, 70821, 68252, 68634, 68364, 68316, 68726, 68784, 60504, 92542, 364, 92543, 1008, 364, 69191, 69390, 68503, 68965, 86409, 75933, 68281, 60353, 60363, 69702, 70245, 68256, 68577, 60353, 78098, 68314, 60481, 60358, 60577, 60447, 60355, 92542, 364, 92543, 525, 11353, 364, 68390, 69390, 68352, 69689, 68804, 60353, 68931, 73286, 83132, 85686, 68352, 70430, 60353, 60407, 72259, 69701, 68287, 60374, 71236, 60359, 69899, 73945, 68352, 68711, 60535, 68607, 68352, 71053, 60455, 60355, 68405, 60353, 69315, 68841, 60409, 86006, 69077, 68913, 60353, 69915, 60357, 71307, 62395, 61342, 60941, 60353, 75504, 69583, 68297, 68253, 70212, 71554, 60355, 68929, 60353, 70142, 68667, 68315, 70972, 68352, 69150, 60353, 60573, 70754, 60403, 70770, 80049, 68474, 75454, 60353, 72816, 68253, 68420, 74740, 82330, 60355, 364, 69156, 60387, 68721, 60353, 60836, 70616, 60353, 74625, 68417, 77146, 68432, 60353, 68760, 69836, 69151, 81497, 60381, 71833, 81268, 68302, 82393, 60353, 72886, 68880, 60677, 72039, 68831, 71684, 68493, 68319, 69806, 68761, 68388, 85064, 60355, 87632, 60510, 77649, 70061, 69183, 68372, 60353, 91987, 68588, 60573, 78835, 60741, 60355, 92542, 364, 2]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 77230, 60353, 68400, 69894, 60403, 69880, 63612, 69166, 64886, 60355, 68364, 68381, 69209, 68377, 60427, 69305, 60353, 68472, 68560, 71631, 68324, 60381, 69396, 70271, 76436, 90530, 71833, 69209, 60355, 69897, 80966, 78747, 68304, 68357, 71228, 60381, 69203, 60353, 60510, 70535, 68324, 69461, 77546, 69238, 76906, 69362, 68559, 60355, 69686, 75630, 76048, 73799, 68352, 71842, 69834, 71280, 60353, 68405, 68865, 60573, 82567, 68304, 69490, 60355, 68931, 78705, 60383, 60353, 89901, 68660, 69396, 71582, 68301, 60355, 92542, 364, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 68505, 68364, 68358, 60375, 60353, 60363, 68571, 70923, 74541, 69702, 68274, 70900, 69233, 60353, 68522, 60887, 69930, 60359, 87245, 60455, 68256, 60353, 72195, 69715, 86038, 60355, 68721, 60353, 70579, 68763, 75936, 74462, 74727, 69034, 60353, 68840, 70637, 70579, 70871, 61274, 64221, 76017, 60355, 79018, 68251, 68592, 69401, 68300, 70923, 77649, 68365, 74112, 60353, 75173, 68518, 68343, 70821, 68252, 68634, 68364, 68316, 68726, 68784, 60504, 92542, 364, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 68390, 69390, 68352, 69689, 68804, 60353, 68931, 73286, 83132, 85686, 68352, 70430, 60353, 60407, 72259, 69701, 68287, 60374, 71236, 60359, 69899, 73945, 68352, 68711, 60535, 68607, 68352, 71053, 60455, 60355, 68405, 60353, 69315, 68841, 60409, 86006, 69077, 68913, 60353, 69915, 60357, 71307, 62395, 61342, 60941, 60353, 75504, 69583, 68297, 68253, 70212, 71554, 60355, 68929, 60353, 70142, 68667, 68315, 70972, 68352, 69150, 60353, 60573, 70754, 60403, 70770, 80049, 68474, 75454, 60353, 72816, 68253, 68420, 74740, 82330, 60355, 364, 69156, 60387, 68721, 60353, 60836, 70616, 60353, 74625, 68417, 77146, 68432, 60353, 68760, 69836, 69151, 81497, 60381, 71833, 81268, 68302, 82393, 60353, 72886, 68880, 60677, 72039, 68831, 71684, 68493, 68319, 69806, 68761, 68388, 85064, 60355, 87632, 60510, 77649, 70061, 69183, 68372, 60353, 91987, 68588, 60573, 78835, 60741, 60355, 92542, 364, 2]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_id[0].keys())\n",
    "print(tokenized_id[0]['input_ids'])\n",
    "print(tokenized_id[0]['attention_mask'])\n",
    "print(tokenized_id[0]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <s><|im_start|> system\n",
      "现在你是一个心理专家，我有一些心理问题，请你用专业的知识帮我解决。<|im_end|> \n",
      "<|im_start|> user\n",
      "医生，我最近总是感到很焦虑，尤其是在学业上。我有个特别崇拜的同学，他好像在各方面都比我优秀，我总觉得自己怎么努力也追不上他，这让我压力特别大。<|im_end|> \n",
      "<|im_start|> assistant\n",
      "你好，首先感谢你对我敞开心扉。你的这种情绪其实很常见，这是由于过度比较和自我期待过高引发的焦虑情绪。我们要认识到每个人都有自己的发展节奏和优势，与他人比较并不是衡量自身价值的唯一标准。你可以试着列出自己在学习和其他方面的优点，同时理解并接纳自己的不足。我们可以一步步来，先从调整自我认知开始。<|im_end|> \n",
      "<|im_start|> user\n",
      "是的，我知道应该理性看待，但就是忍不住会去比较。我甚至晚上会因为这个睡不着觉，总想着怎样才能像他那样出色。<|im_end|> \n",
      "<|im_start|> assistant\n",
      "了解你的情况后，我建议你在睡前尝试进行放松训练，比如深呼吸、冥想等方法，有助于改善睡眠质量。另外，设定实际可达的目标也是很重要的，避免给自己设定过于严苛的标准。你是否可以具体描述一下你在学业上的困扰，我们一起看看如何制定一个适合你的个人提升计划？<|im_end|> \n",
      "<|im_start|> user\n",
      "我在数学方面总是比他落后很多，我尝试了很多方法提高，但还是觉得力不从心。<|im_end|> \n",
      "<|im_start|> assistant\n",
      "对于数学学习困难的问题，我们可以探讨更具针对性的学习策略，如分解复杂问题为小块、寻找优质的学习资源或参加学习小组等。同时，也要建立对失败的正确认识，失败是成功的垫脚石，每一次错误都是我们进步的机会。接下来，我会推荐一些有效的学习技巧，并鼓励你定期与我分享进展，以便我们根据实际情况进行调整。\n",
      "医生：另外，请记住，寻求帮助也是一种能力，如果你感到持续的压力和焦虑影响了生活和学习，不妨考虑找学校的心理辅导老师或者进一步接受专业心理咨询。心理健康与学业成就同样重要，让我们一起关注并呵护它。<|im_end|> \n",
      "</s>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(tokenized_id[0]['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 你好，首先感谢你对我敞开心扉。你的这种情绪其实很常见，这是由于过度比较和自我期待过高引发的焦虑情绪。我们要认识到每个人都有自己的发展节奏和优势，与他人比较并不是衡量自身价值的唯一标准。你可以试着列出自己在学习和其他方面的优点，同时理解并接纳自己的不足。我们可以一步步来，先从调整自我认知开始。<|im_end|> \\n了解你的情况后，我建议你在睡前尝试进行放松训练，比如深呼吸、冥想等方法，有助于改善睡眠质量。另外，设定实际可达的目标也是很重要的，避免给自己设定过于严苛的标准。你是否可以具体描述一下你在学业上的困扰，我们一起看看如何制定一个适合你的个人提升计划？<|im_end|> \\n对于数学学习困难的问题，我们可以探讨更具针对性的学习策略，如分解复杂问题为小块、寻找优质的学习资源或参加学习小组等。同时，也要建立对失败的正确认识，失败是成功的垫脚石，每一次错误都是我们进步的机会。接下来，我会推荐一些有效的学习技巧，并鼓励你定期与我分享进展，以便我们根据实际情况进行调整。\\n医生：另外，请记住，寻求帮助也是一种能力，如果你感到持续的压力和焦虑影响了生活和学习，不妨考虑找学校的心理辅导老师或者进一步接受专业心理咨询。心理健康与学业成就同样重要，让我们一起关注并呵护它。<|im_end|> \\n</s>'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(list(filter(lambda x: x != -100, tokenized_id[0][\"labels\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,                      # 是否在4位精度下加载模型。如果设置为True，则在4位精度下加载模型。\n",
    "    load_in_8bit=False,\n",
    "    llm_int8_threshold=6.0,\n",
    "    llm_int8_has_fp16_weight=False,\n",
    "    bnb_4bit_compute_dtype=torch.float16,   # 4位精度计算的数据类型。这里设置为torch.float16，表示使用半精度浮点数。\n",
    "    bnb_4bit_quant_type='nf4',              # 4位精度量化的类型。这里设置为\"nf4\"，表示使用nf4量化类型。 nf4: 4bit-NormalFloat\n",
    "    bnb_4bit_use_double_quant=True,         # 是否使用双精度量化。如果设置为True，则使用双精度量化。\n",
    ")\n",
    "quantization_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map='auto',\n",
    "    low_cpu_mem_usage=True,             # 是否使用低CPU内存，使用 device_map 参数必须为 True\n",
    "    quantization_config=quantization_config,\n",
    ")\n",
    "model.enable_input_require_grads()      # 开启梯度检查点时，要执行该方法\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"model.device: {model.device}, model.dtype: {model.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, TaskType, get_peft_model, prepare_model_for_kbit_training, load_peft_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/docs/peft/developer_guides/quantization\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False,   # 训练模式\n",
    "    r=64,                   # Lora 秩\n",
    "    target_modules=['wqkv', 'wo', 'w1', 'w2', 'w3'],\n",
    "    lora_alpha=16,          # Lora alaph，具体作用参见 Lora 原理\n",
    "    lora_dropout=0.1,       # Dropout 比例\n",
    "    bias='none'\n",
    ")\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_peft_model(model, config)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 配置训练参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=work_dir,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    learning_rate=2e-4,\n",
    "    gradient_checkpointing=True,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=16,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",  # epoch or steps\n",
    "    save_steps=1,           # 每个epoch保存一次模型\n",
    "    save_total_limit=3,\n",
    "    save_on_each_node=True,\n",
    "    warmup_ratio=0.03,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    bf16 = False,   # 指定训练时的类型\n",
    "    fp16 = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_id,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
